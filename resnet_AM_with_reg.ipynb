{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for inference\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models                   \n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray, percentile, tile\n",
    "import torch.nn as nn\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torchvision import transforms\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "denormalize = transforms.Normalize(mean = [-0.485/0.229, -0.456/0.224, -0.406/0.225], std = [1/0.229, 1/0.224, 1/0.225] )\n",
    "def image_converter(im):\n",
    "    im_copy = im.cpu()\n",
    "    \n",
    "    im_copy = denormalize(im_copy.clone().detach()).numpy()\n",
    "    im_copy = im_copy.transpose(1,2,0)\n",
    "    im_copy = im_copy.clip(0, 1) \n",
    "    return im_copy\n",
    "\n",
    "def layer_hook(act_dict, layer_name):\n",
    "    def hook(module, input, output):\n",
    "        act_dict[layer_name] = output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter(model, img, jitter_t, layer_activation, layer_name, unit):\n",
    "    sum = 0\n",
    "    for i in range(10):\n",
    "        temp_img = img\n",
    "        tao = random.randint(0, jitter_t)\n",
    "        temp_img = torch.add(temp_img, tao)\n",
    "        model(temp_img)\n",
    "        layer_out = layer_activation[layer_name]\n",
    "        sum = torch.add(sum, layer_out[0][unit])\n",
    "    jitter_loss = sum / 10\n",
    "    jitter_loss.requires_grad_(True)\n",
    "    jitter_loss.retain_grad() \n",
    "    jitter_loss.backward(retain_graph=True)\n",
    "    jitter_grad = jitter_loss.grad.detach()\n",
    "    return jitter_loss.detach(), jitter_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv(img, img_grad):\n",
    "    bs_img, c_img, h_img, w_img = img.size()\n",
    "    w = torch.sum(torch.pow(img[:,:,:,:-1] - img[:,:,:,1:], 2))\n",
    "    h = torch.sum(torch.pow(img[:,:,:-1,:] - img[:,:,1:,:], 2))\n",
    "    tv_loss = (1/(torch.norm(img_grad) * h_img * w_img) * (h + w))\n",
    "    tv_loss.requires_grad_(True)\n",
    "    tv_loss.retain_grad() \n",
    "    tv_loss.backward(retain_graph=True)\n",
    "    tv_grad = tv_loss.grad.detach()\n",
    "    return tv_loss.detach(), tv_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_max(model, \n",
    "    inp_img, \n",
    "    layer_activation, \n",
    "    layer_name, \n",
    "    unit, \n",
    "    steps=100, \n",
    "    alpha=torch.tensor(1),\n",
    "    TV = False,\n",
    "    Jitter = False,\n",
    "    Regular = False,\n",
    "    jitter_t = 20,\n",
    "    jitter_alpha = 0.05,\n",
    "    tv_alpha = 0.05,\n",
    "    show_img = False\n",
    "    ):\n",
    "\n",
    "    best_activation = -float('inf')\n",
    "    min_loss = float('inf')\n",
    "    best_img = inp_img\n",
    "    for k in range(steps):\n",
    "        inp_img.requires_grad_(True)\n",
    "        inp_img.retain_grad() \n",
    "        inp_img = inp_img.to(device)\n",
    "        old_norm = torch.norm(inp_img)\n",
    "        # Propagate image\n",
    "        model(inp_img)\n",
    "        layer_out = layer_activation[layer_name]\n",
    "        # Compute gradients\n",
    "        layer_out[0][unit].backward(retain_graph=True)\n",
    "        img_grad = inp_img.grad\n",
    "            \n",
    "        # Gradient Step\n",
    "        inp_img = torch.add(inp_img, torch.mul(img_grad.detach(), alpha))\n",
    "\n",
    "        act_loss = layer_out[0][unit]\n",
    "        #Jitter\n",
    "        jitter_loss = torch.tensor(0)\n",
    "        jitter_grad = 0\n",
    "        if Jitter and k % 10 == 0:\n",
    "            jitter_loss, jitter_grad = jitter(model, inp_img, jitter_t, layer_activation, layer_name, unit)\n",
    "        if TV:\n",
    "            tv_loss, tv_grad = tv(inp_img, img_grad)\n",
    "\n",
    "        # Keep highest activation\n",
    "        loss = -1 * act_loss\n",
    "        if Jitter:\n",
    "            loss -= jitter_alpha * jitter_loss\n",
    "        if TV:\n",
    "            loss += tv_alpha * tv_loss\n",
    "        if Regular:\n",
    "            if Jitter:\n",
    "              inp_img = torch.add(inp_img, torch.mul(jitter_grad, alpha*jitter_alpha))\n",
    "            if TV:\n",
    "              inp_img = torch.add(inp_img, torch.mul(tv_grad, -alpha*tv_alpha))\n",
    "        \n",
    "        new_norm = torch.norm(inp_img)\n",
    "        inp_img = torch.mul(inp_img, old_norm/new_norm)\n",
    "        if loss < min_loss:\n",
    "            if not Jitter or k % 10 != 10:\n",
    "                jitter_loss, jitter_grad = jitter(model, inp_img, jitter_t, layer_activation, layer_name, unit)\n",
    "            if not TV:\n",
    "                tv_loss, tv_grad = tv(inp_img, img_grad)\n",
    "            best_activation = act_loss, jitter_loss, tv_loss, loss\n",
    "            min_loss = loss\n",
    "            best_img = inp_img\n",
    "\n",
    "        if show_img and k == steps-1:\n",
    "            final_image = image_converter(inp_img.squeeze(0))\n",
    "            plt.imshow(final_image)\n",
    "            plt.show()        \n",
    "            print('step: ', k, 'activation: ', layer_out[0][unit])\n",
    "        \n",
    "    return (best_activation, best_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\phili/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained = True)\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\n",
    "\n",
    "resnet50.eval().to(device)\n",
    "\n",
    "alexnet = models.alexnet(weights='IMAGENET1K_V1')\n",
    "alexnet.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_img():\n",
    "  inp = torch.rand((1, 3, 227, 227))\n",
    "  inp.requires_grad_(True)\n",
    "  return inp.to(device)\n",
    "# convert (1, 3, 227, 227) Torch tensor into 227*227 element numpy array, averaging across RGB channels\n",
    "def np_data(img):\n",
    "    img = denormalize(img.squeeze().detach().cpu())\n",
    "    img = torch.mean(img, 0)\n",
    "    img = torch.flatten(img)\n",
    "    img = img.numpy()\n",
    "    return img\n",
    "def get_hist(arr, title):\n",
    "    hist, bin = np.histogram(arr)\n",
    "    plt.hist(arr, bins=bin)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 130\n",
    "steps = 200\n",
    "alpha = torch.tensor(1.5)\n",
    "def experiment(model, TV, Jitter, jitter_t=0, jitter_alpha=0, tv_alpha=0, trials=10):\n",
    "    # In order: activation, jitter, tv, and total losses\n",
    "    losses = [], [], [], []\n",
    "    for t in range(trials):\n",
    "        # starting image\n",
    "        orig_img = reset_img()\n",
    "        inp = orig_img\n",
    "        # outputs of image through both neural nets\n",
    "        results = model(inp)\n",
    "        value = results.detach().cpu().numpy()\n",
    "        # max outputs of image through both neural nets\n",
    "        k = max(value[0])\n",
    "        act_dict = {}\n",
    "        layer_name = 'classifier_final'\n",
    "        list(model.children())[-1].register_forward_hook(layer_hook(act_dict, layer_name))\n",
    "        \n",
    "        activation, output = act_max(model=model,\n",
    "                    inp_img=inp,\n",
    "                    layer_activation=act_dict,\n",
    "                    layer_name=layer_name,\n",
    "                    unit=unit,\n",
    "                    steps=steps,\n",
    "                    alpha=alpha,\n",
    "                    TV=TV,\n",
    "                    Jitter=Jitter,\n",
    "                    Regular=True,\n",
    "                    jitter_t=jitter_t,\n",
    "                    jitter_alpha=jitter_alpha,\n",
    "                    tv_alpha=tv_alpha,\n",
    "                    show_img=False,\n",
    "                    )\n",
    "        for i in range(4):\n",
    "            if isinstance(activation[i], int):\n",
    "                print(i)\n",
    "            losses[i].append(activation[i].detach().cpu().numpy().item())\n",
    "        out = np_data(output)\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Completed trial:\", t)\n",
    "    names = [\"Activations:\", \"Jitter losses:\", \"TV losses:\", \"Total losses:\"], [\"Average activation:\", \"Average jitter loss:\", \"Average TV loss:\", \"Average total loss:\"]\n",
    "    for i in range(4):\n",
    "        print(names[0][i], str(losses[i]))\n",
    "        print(names[1][i], sum(losses[i])/trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed trial: 0\n",
      "Completed trial: 1\n"
     ]
    }
   ],
   "source": [
    "experiment(alexnet, TV=True, Jitter=True, jitter_t=10, jitter_alpha=0.01, tv_alpha=0.001, trials=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet50, TV=False, Jitter=True, jitter_t=10, jitter_alpha=0.1, tv_alpha=0, trials=10  \n",
    " - Activations: [163.57022094726562, 171.38491821289062, 177.36441040039062, 184.45797729492188, 174.5690460205078, 162.1881103515625, 173.3818359375, 167.202392578125, 176.84043884277344, 178.08633422851562]\n",
    " - Average activation: 172.90456848144532\n",
    " - Jitter losses: [22.103370666503906, 34.036346435546875, 8.708541870117188, 19.32915496826172, 38.63886260986328, 27.92671775817871, 14.243896484375, 23.848962783813477, 12.266249656677246, 39.02633285522461]\n",
    " - Average jitter loss: 24.0128436088562\n",
    " - TV losses: [0.02318560890853405, 0.027121976017951965, 0.028241293504834175, 0.04551585391163826, 0.025176187977194786, 0.026284033432602882, 0.026428097859025, 0.02534600719809532, 0.028803151100873947, 0.029583383351564407]\n",
    " - Average TV loss: 0.02856855932623148\n",
    " - Total losses: [-167.22222900390625, -171.38491821289062, -180.71128845214844, -184.45797729492188, -174.5690460205078, -164.54434204101562, -178.4657440185547, -170.62872314453125, -180.0749053955078, -181.38262939453125]\n",
    " - Average total loss: -175.34418029785155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
